{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e37281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30441b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/credit-score/ready_train.csv'\n",
    "test_path  = 'data/credit-score/ready_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path).values\n",
    "# test_data  = pd.read_csv(test_path).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1e812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data[:, :-1]\n",
    "train_y = keras.utils.to_categorical(train_data[:, -1], num_classes=3)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_x = StandardScaler().fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0effc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8794601",
   "metadata": {},
   "source": [
    "### Definindo algumas redes neurais para o problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677ad5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn1():    # NN simples: uma camada de input, uma de output\n",
    "    model = keras.Sequential()\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))    # 37 atributos\n",
    "    #model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=3, kernel_initializer='he_normal', activation='softmax'))  #  3 classes\n",
    "    return model\n",
    "\n",
    "def nn2():    # NN mais robusta: uma hidden layer com 37 neurônios\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=3, kernel_initializer='he_normal', activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def nn3():    # NN com hidden layer maior (74 neurônios agora)\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=74, kernel_initializer='he_normal', activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units=3, kernel_initializer='he_normal', activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def nn4():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=74, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=3, kernel_initializer='he_normal', activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def nn5():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=37, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=14, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=14, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=14, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=3, kernel_initializer='he_normal', activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147537da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 16:18:31.769567: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-28 16:18:31.769876: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 16:18:31.771052: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-07-28 16:18:31.836220: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-28 16:18:31.853484: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2394580000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.8387 - accuracy: 0.6097 - val_loss: 0.7108 - val_accuracy: 0.6806\n",
      "Epoch 2/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.7081 - accuracy: 0.6806 - val_loss: 0.6963 - val_accuracy: 0.6899\n",
      "Epoch 3/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6935 - accuracy: 0.6919 - val_loss: 0.6892 - val_accuracy: 0.6944\n",
      "Epoch 4/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6825 - accuracy: 0.6952 - val_loss: 0.6875 - val_accuracy: 0.6949\n",
      "Epoch 5/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6807 - accuracy: 0.6983 - val_loss: 0.6839 - val_accuracy: 0.7011\n",
      "Epoch 6/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6786 - accuracy: 0.7009 - val_loss: 0.6803 - val_accuracy: 0.6993\n",
      "Epoch 7/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6760 - accuracy: 0.7036 - val_loss: 0.6807 - val_accuracy: 0.7001\n",
      "Epoch 8/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6724 - accuracy: 0.7031 - val_loss: 0.6800 - val_accuracy: 0.6996\n",
      "Epoch 9/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6694 - accuracy: 0.7061 - val_loss: 0.6768 - val_accuracy: 0.7020\n",
      "Epoch 10/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6682 - accuracy: 0.7037 - val_loss: 0.6780 - val_accuracy: 0.7007\n",
      "Epoch 11/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6659 - accuracy: 0.7090 - val_loss: 0.6749 - val_accuracy: 0.6993\n",
      "Epoch 12/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6650 - accuracy: 0.7059 - val_loss: 0.6751 - val_accuracy: 0.7006\n",
      "Epoch 13/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6643 - accuracy: 0.7092 - val_loss: 0.6744 - val_accuracy: 0.7039\n",
      "Epoch 14/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6639 - accuracy: 0.7098 - val_loss: 0.6736 - val_accuracy: 0.7054\n",
      "Epoch 15/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6642 - accuracy: 0.7080 - val_loss: 0.6778 - val_accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6621 - accuracy: 0.7113 - val_loss: 0.6745 - val_accuracy: 0.7041\n",
      "Epoch 17/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6548 - accuracy: 0.7124 - val_loss: 0.6737 - val_accuracy: 0.7018\n",
      "Epoch 18/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6578 - accuracy: 0.7129 - val_loss: 0.6724 - val_accuracy: 0.7032\n",
      "Epoch 19/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6530 - accuracy: 0.7163 - val_loss: 0.6716 - val_accuracy: 0.7031\n",
      "Epoch 20/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6613 - accuracy: 0.7110 - val_loss: 0.6721 - val_accuracy: 0.7027\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6663 - accuracy: 0.7055\n"
     ]
    }
   ],
   "source": [
    "model = nn1()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=64, epochs=20, validation_split=0.1)\n",
    "_ = model.evaluate(x=x_test, y=y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b60806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.8201 - accuracy: 0.6178 - val_loss: 0.7015 - val_accuracy: 0.6872\n",
      "Epoch 2/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6936 - accuracy: 0.6920 - val_loss: 0.6948 - val_accuracy: 0.6934\n",
      "Epoch 3/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6818 - accuracy: 0.6996 - val_loss: 0.6834 - val_accuracy: 0.7006\n",
      "Epoch 4/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6708 - accuracy: 0.7005 - val_loss: 0.6776 - val_accuracy: 0.7044\n",
      "Epoch 5/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6676 - accuracy: 0.7050 - val_loss: 0.6803 - val_accuracy: 0.7024\n",
      "Epoch 6/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6616 - accuracy: 0.7058 - val_loss: 0.6724 - val_accuracy: 0.7018\n",
      "Epoch 7/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6535 - accuracy: 0.7119 - val_loss: 0.6753 - val_accuracy: 0.7041\n",
      "Epoch 8/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6543 - accuracy: 0.7111 - val_loss: 0.6716 - val_accuracy: 0.7028\n",
      "Epoch 9/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6493 - accuracy: 0.7138 - val_loss: 0.6696 - val_accuracy: 0.7096\n",
      "Epoch 10/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6485 - accuracy: 0.7146 - val_loss: 0.6663 - val_accuracy: 0.7059\n",
      "Epoch 11/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6433 - accuracy: 0.7174 - val_loss: 0.6652 - val_accuracy: 0.7106\n",
      "Epoch 12/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6337 - accuracy: 0.7233 - val_loss: 0.6715 - val_accuracy: 0.7060\n",
      "Epoch 13/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6360 - accuracy: 0.7218 - val_loss: 0.6673 - val_accuracy: 0.7102\n",
      "Epoch 14/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6343 - accuracy: 0.7216 - val_loss: 0.6674 - val_accuracy: 0.7011\n",
      "Epoch 15/20\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 0.6344 - accuracy: 0.7199 - val_loss: 0.6634 - val_accuracy: 0.7113\n",
      "Epoch 16/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6334 - accuracy: 0.7226 - val_loss: 0.6634 - val_accuracy: 0.7098\n",
      "Epoch 17/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6329 - accuracy: 0.7233 - val_loss: 0.6649 - val_accuracy: 0.7094\n",
      "Epoch 18/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6320 - accuracy: 0.7249 - val_loss: 0.6641 - val_accuracy: 0.7067\n",
      "Epoch 19/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6255 - accuracy: 0.7266 - val_loss: 0.6622 - val_accuracy: 0.7118\n",
      "Epoch 20/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6287 - accuracy: 0.7259 - val_loss: 0.6610 - val_accuracy: 0.7151\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6457 - accuracy: 0.7140\n"
     ]
    }
   ],
   "source": [
    "model = nn2()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=64, epochs=20, validation_split=0.1)\n",
    "_ = model.evaluate(x=x_test, y=y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88fe118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.8089 - accuracy: 0.6308 - val_loss: 0.6966 - val_accuracy: 0.6882\n",
      "Epoch 2/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6937 - accuracy: 0.6933 - val_loss: 0.6860 - val_accuracy: 0.6973\n",
      "Epoch 3/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6754 - accuracy: 0.7023 - val_loss: 0.6795 - val_accuracy: 0.7003\n",
      "Epoch 4/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6666 - accuracy: 0.7037 - val_loss: 0.6729 - val_accuracy: 0.7046\n",
      "Epoch 5/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6598 - accuracy: 0.7084 - val_loss: 0.6715 - val_accuracy: 0.7074\n",
      "Epoch 6/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6528 - accuracy: 0.7130 - val_loss: 0.6722 - val_accuracy: 0.7014\n",
      "Epoch 7/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6483 - accuracy: 0.7157 - val_loss: 0.6654 - val_accuracy: 0.7107\n",
      "Epoch 8/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6428 - accuracy: 0.7164 - val_loss: 0.6602 - val_accuracy: 0.7142\n",
      "Epoch 9/20\n",
      "1266/1266 [==============================] - 6s 4ms/step - loss: 0.6459 - accuracy: 0.7150 - val_loss: 0.6649 - val_accuracy: 0.7152\n",
      "Epoch 10/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6364 - accuracy: 0.7219 - val_loss: 0.6602 - val_accuracy: 0.7129\n",
      "Epoch 11/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6295 - accuracy: 0.7242 - val_loss: 0.6607 - val_accuracy: 0.7137\n",
      "Epoch 12/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6271 - accuracy: 0.7248 - val_loss: 0.6567 - val_accuracy: 0.7156\n",
      "Epoch 13/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6265 - accuracy: 0.7275 - val_loss: 0.6560 - val_accuracy: 0.7134\n",
      "Epoch 14/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6252 - accuracy: 0.7277 - val_loss: 0.6556 - val_accuracy: 0.7129\n",
      "Epoch 15/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6201 - accuracy: 0.7305 - val_loss: 0.6593 - val_accuracy: 0.7087\n",
      "Epoch 16/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6201 - accuracy: 0.7280 - val_loss: 0.6567 - val_accuracy: 0.7151\n",
      "Epoch 17/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6177 - accuracy: 0.7308 - val_loss: 0.6547 - val_accuracy: 0.7154\n",
      "Epoch 18/20\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.6148 - accuracy: 0.7334 - val_loss: 0.6552 - val_accuracy: 0.7182\n",
      "Epoch 19/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6101 - accuracy: 0.7349 - val_loss: 0.6518 - val_accuracy: 0.7161\n",
      "Epoch 20/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6122 - accuracy: 0.7343 - val_loss: 0.6556 - val_accuracy: 0.7154\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6479 - accuracy: 0.7161\n"
     ]
    }
   ],
   "source": [
    "model = nn3()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=64, epochs=20, validation_split=0.1)\n",
    "_ = model.evaluate(x=x_test, y=y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "befdb4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.7983 - accuracy: 0.6285 - val_loss: 0.6971 - val_accuracy: 0.6904\n",
      "Epoch 2/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6886 - accuracy: 0.6938 - val_loss: 0.6823 - val_accuracy: 0.6969\n",
      "Epoch 3/20\n",
      "1266/1266 [==============================] - 8s 6ms/step - loss: 0.6697 - accuracy: 0.7050 - val_loss: 0.6748 - val_accuracy: 0.7043\n",
      "Epoch 4/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6571 - accuracy: 0.7084 - val_loss: 0.6686 - val_accuracy: 0.7059\n",
      "Epoch 5/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6534 - accuracy: 0.7111 - val_loss: 0.6675 - val_accuracy: 0.7032\n",
      "Epoch 6/20\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.6426 - accuracy: 0.7163 - val_loss: 0.6594 - val_accuracy: 0.7133\n",
      "Epoch 7/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6384 - accuracy: 0.7216 - val_loss: 0.6575 - val_accuracy: 0.7087\n",
      "Epoch 8/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6322 - accuracy: 0.7221 - val_loss: 0.6547 - val_accuracy: 0.7103\n",
      "Epoch 9/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6283 - accuracy: 0.7268 - val_loss: 0.6484 - val_accuracy: 0.7158\n",
      "Epoch 10/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6180 - accuracy: 0.7335 - val_loss: 0.6478 - val_accuracy: 0.7169\n",
      "Epoch 11/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6074 - accuracy: 0.7375 - val_loss: 0.6459 - val_accuracy: 0.7216\n",
      "Epoch 12/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6010 - accuracy: 0.7397 - val_loss: 0.6485 - val_accuracy: 0.7149\n",
      "Epoch 13/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6030 - accuracy: 0.7390 - val_loss: 0.6425 - val_accuracy: 0.7190\n",
      "Epoch 14/20\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5996 - accuracy: 0.7395 - val_loss: 0.6367 - val_accuracy: 0.7261\n",
      "Epoch 15/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5926 - accuracy: 0.7443 - val_loss: 0.6392 - val_accuracy: 0.7262\n",
      "Epoch 16/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5851 - accuracy: 0.7480 - val_loss: 0.6365 - val_accuracy: 0.7288\n",
      "Epoch 17/20\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5839 - accuracy: 0.7480 - val_loss: 0.6348 - val_accuracy: 0.7244\n",
      "Epoch 18/20\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5764 - accuracy: 0.7524 - val_loss: 0.6398 - val_accuracy: 0.7239\n",
      "Epoch 19/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5756 - accuracy: 0.7521 - val_loss: 0.6360 - val_accuracy: 0.7263\n",
      "Epoch 20/20\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5708 - accuracy: 0.7552 - val_loss: 0.6304 - val_accuracy: 0.7301\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6216 - accuracy: 0.7343\n"
     ]
    }
   ],
   "source": [
    "model = nn4()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=64, epochs=20, validation_split=0.1)\n",
    "_ = model.evaluate(x=x_test, y=y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a4a93c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.7946 - accuracy: 0.6287 - val_loss: 0.6961 - val_accuracy: 0.6878\n",
      "Epoch 2/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6894 - accuracy: 0.6938 - val_loss: 0.6770 - val_accuracy: 0.7004\n",
      "Epoch 3/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6716 - accuracy: 0.7046 - val_loss: 0.6712 - val_accuracy: 0.7013\n",
      "Epoch 4/100\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.6617 - accuracy: 0.7079 - val_loss: 0.6657 - val_accuracy: 0.7077\n",
      "Epoch 5/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6525 - accuracy: 0.7135 - val_loss: 0.6701 - val_accuracy: 0.7074\n",
      "Epoch 6/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6443 - accuracy: 0.7170 - val_loss: 0.6662 - val_accuracy: 0.7061\n",
      "Epoch 7/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6399 - accuracy: 0.7211 - val_loss: 0.6608 - val_accuracy: 0.7086\n",
      "Epoch 8/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6306 - accuracy: 0.7224 - val_loss: 0.6575 - val_accuracy: 0.7106\n",
      "Epoch 9/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6287 - accuracy: 0.7249 - val_loss: 0.6594 - val_accuracy: 0.7080\n",
      "Epoch 10/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6227 - accuracy: 0.7277 - val_loss: 0.6522 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6149 - accuracy: 0.7321 - val_loss: 0.6503 - val_accuracy: 0.7159\n",
      "Epoch 12/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6081 - accuracy: 0.7340 - val_loss: 0.6514 - val_accuracy: 0.7108\n",
      "Epoch 13/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6061 - accuracy: 0.7373 - val_loss: 0.6534 - val_accuracy: 0.7181\n",
      "Epoch 14/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6030 - accuracy: 0.7368 - val_loss: 0.6500 - val_accuracy: 0.7157\n",
      "Epoch 15/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5963 - accuracy: 0.7426 - val_loss: 0.6490 - val_accuracy: 0.7198\n",
      "Epoch 16/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5927 - accuracy: 0.7425 - val_loss: 0.6463 - val_accuracy: 0.7191\n",
      "Epoch 17/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5894 - accuracy: 0.7440 - val_loss: 0.6463 - val_accuracy: 0.7188\n",
      "Epoch 18/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5843 - accuracy: 0.7456 - val_loss: 0.6420 - val_accuracy: 0.7187\n",
      "Epoch 19/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5797 - accuracy: 0.7502 - val_loss: 0.6399 - val_accuracy: 0.7209\n",
      "Epoch 20/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5743 - accuracy: 0.7508 - val_loss: 0.6412 - val_accuracy: 0.7214\n",
      "Epoch 21/100\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5741 - accuracy: 0.7514 - val_loss: 0.6428 - val_accuracy: 0.7210\n",
      "Epoch 22/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5700 - accuracy: 0.7540 - val_loss: 0.6409 - val_accuracy: 0.7216\n",
      "Epoch 23/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5682 - accuracy: 0.7546 - val_loss: 0.6358 - val_accuracy: 0.7223\n",
      "Epoch 24/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5588 - accuracy: 0.7581 - val_loss: 0.6360 - val_accuracy: 0.7258\n",
      "Epoch 25/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5602 - accuracy: 0.7578 - val_loss: 0.6445 - val_accuracy: 0.7233\n",
      "Epoch 26/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5563 - accuracy: 0.7613 - val_loss: 0.6334 - val_accuracy: 0.7249\n",
      "Epoch 27/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5548 - accuracy: 0.7619 - val_loss: 0.6329 - val_accuracy: 0.7257\n",
      "Epoch 28/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5523 - accuracy: 0.7631 - val_loss: 0.6337 - val_accuracy: 0.7283\n",
      "Epoch 29/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5436 - accuracy: 0.7657 - val_loss: 0.6297 - val_accuracy: 0.7348\n",
      "Epoch 30/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5487 - accuracy: 0.7629 - val_loss: 0.6309 - val_accuracy: 0.7303\n",
      "Epoch 31/100\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5473 - accuracy: 0.7633 - val_loss: 0.6334 - val_accuracy: 0.7343\n",
      "Epoch 32/100\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5424 - accuracy: 0.7677 - val_loss: 0.6326 - val_accuracy: 0.7348\n",
      "Epoch 33/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5382 - accuracy: 0.7687 - val_loss: 0.6372 - val_accuracy: 0.7336\n",
      "Epoch 34/100\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5352 - accuracy: 0.7725 - val_loss: 0.6302 - val_accuracy: 0.7323\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6231 - accuracy: 0.7398\n"
     ]
    }
   ],
   "source": [
    "# Treinando até parar de melhorar a validation loss\n",
    "model = nn4()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=64, epochs=100, validation_split=0.1,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
    "_ = model.evaluate(x=x_test, y=y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed030e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.8714 - accuracy: 0.5955 - val_loss: 0.7051 - val_accuracy: 0.6871\n",
      "Epoch 2/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.6900 - val_loss: 0.6906 - val_accuracy: 0.6893\n",
      "Epoch 3/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6783 - accuracy: 0.6967 - val_loss: 0.6799 - val_accuracy: 0.6982\n",
      "Epoch 4/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6692 - accuracy: 0.7028 - val_loss: 0.6770 - val_accuracy: 0.6988\n",
      "Epoch 5/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6629 - accuracy: 0.7052 - val_loss: 0.6720 - val_accuracy: 0.7013\n",
      "Epoch 6/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6499 - accuracy: 0.7164 - val_loss: 0.6680 - val_accuracy: 0.7046\n",
      "Epoch 7/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6480 - accuracy: 0.7145 - val_loss: 0.6727 - val_accuracy: 0.7027\n",
      "Epoch 8/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6482 - accuracy: 0.7142 - val_loss: 0.6688 - val_accuracy: 0.6992\n",
      "Epoch 9/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6418 - accuracy: 0.7192 - val_loss: 0.6658 - val_accuracy: 0.7037\n",
      "Epoch 10/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6434 - accuracy: 0.7153 - val_loss: 0.6623 - val_accuracy: 0.7024\n",
      "Epoch 11/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6367 - accuracy: 0.7196 - val_loss: 0.6590 - val_accuracy: 0.7093\n",
      "Epoch 12/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6365 - accuracy: 0.7201 - val_loss: 0.6613 - val_accuracy: 0.7110\n",
      "Epoch 13/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6263 - accuracy: 0.7260 - val_loss: 0.6596 - val_accuracy: 0.7124\n",
      "Epoch 14/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.6288 - accuracy: 0.7250 - val_loss: 0.6640 - val_accuracy: 0.7101\n",
      "Epoch 15/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6262 - accuracy: 0.7271 - val_loss: 0.6578 - val_accuracy: 0.7103\n",
      "Epoch 16/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6218 - accuracy: 0.7277 - val_loss: 0.6610 - val_accuracy: 0.7108\n",
      "Epoch 17/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6222 - accuracy: 0.7276 - val_loss: 0.6549 - val_accuracy: 0.7134\n",
      "Epoch 18/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6207 - accuracy: 0.7284 - val_loss: 0.6545 - val_accuracy: 0.7139\n",
      "Epoch 19/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6192 - accuracy: 0.7293 - val_loss: 0.6524 - val_accuracy: 0.7144\n",
      "Epoch 20/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6126 - accuracy: 0.7317 - val_loss: 0.6550 - val_accuracy: 0.7128\n",
      "Epoch 21/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6106 - accuracy: 0.7352 - val_loss: 0.6488 - val_accuracy: 0.7143\n",
      "Epoch 22/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6123 - accuracy: 0.7328 - val_loss: 0.6477 - val_accuracy: 0.7170\n",
      "Epoch 23/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6061 - accuracy: 0.7347 - val_loss: 0.6485 - val_accuracy: 0.7167\n",
      "Epoch 24/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6032 - accuracy: 0.7385 - val_loss: 0.6453 - val_accuracy: 0.7180\n",
      "Epoch 25/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5985 - accuracy: 0.7404 - val_loss: 0.6448 - val_accuracy: 0.7177\n",
      "Epoch 26/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.6034 - accuracy: 0.7377 - val_loss: 0.6476 - val_accuracy: 0.7186\n",
      "Epoch 27/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6035 - accuracy: 0.7378 - val_loss: 0.6434 - val_accuracy: 0.7173\n",
      "Epoch 28/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.6009 - accuracy: 0.7376 - val_loss: 0.6411 - val_accuracy: 0.7231\n",
      "Epoch 29/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5994 - accuracy: 0.7408 - val_loss: 0.6387 - val_accuracy: 0.7217\n",
      "Epoch 30/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5973 - accuracy: 0.7410 - val_loss: 0.6429 - val_accuracy: 0.7220\n",
      "Epoch 31/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5906 - accuracy: 0.7444 - val_loss: 0.6440 - val_accuracy: 0.7207\n",
      "Epoch 32/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5913 - accuracy: 0.7443 - val_loss: 0.6414 - val_accuracy: 0.7231\n",
      "Epoch 33/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5912 - accuracy: 0.7444 - val_loss: 0.6413 - val_accuracy: 0.7206\n",
      "Epoch 34/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5903 - accuracy: 0.7448 - val_loss: 0.6375 - val_accuracy: 0.7231\n",
      "Epoch 35/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5879 - accuracy: 0.7446 - val_loss: 0.6356 - val_accuracy: 0.7223\n",
      "Epoch 36/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5877 - accuracy: 0.7441 - val_loss: 0.6356 - val_accuracy: 0.7246\n",
      "Epoch 37/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5856 - accuracy: 0.7467 - val_loss: 0.6390 - val_accuracy: 0.7223\n",
      "Epoch 38/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5844 - accuracy: 0.7480 - val_loss: 0.6345 - val_accuracy: 0.7320\n",
      "Epoch 39/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5832 - accuracy: 0.7492 - val_loss: 0.6366 - val_accuracy: 0.7249\n",
      "Epoch 40/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5837 - accuracy: 0.7472 - val_loss: 0.6334 - val_accuracy: 0.7300\n",
      "Epoch 41/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5846 - accuracy: 0.7455 - val_loss: 0.6373 - val_accuracy: 0.7260\n",
      "Epoch 42/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5792 - accuracy: 0.7492 - val_loss: 0.6320 - val_accuracy: 0.7323\n",
      "Epoch 43/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5795 - accuracy: 0.7515 - val_loss: 0.6339 - val_accuracy: 0.7303\n",
      "Epoch 44/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5808 - accuracy: 0.7485 - val_loss: 0.6417 - val_accuracy: 0.7268\n",
      "Epoch 45/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5799 - accuracy: 0.7507 - val_loss: 0.6417 - val_accuracy: 0.7277\n",
      "Epoch 46/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5776 - accuracy: 0.7516 - val_loss: 0.6374 - val_accuracy: 0.7274\n",
      "Epoch 47/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5747 - accuracy: 0.7545 - val_loss: 0.6308 - val_accuracy: 0.7284\n",
      "Epoch 48/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5740 - accuracy: 0.7545 - val_loss: 0.6308 - val_accuracy: 0.7304\n",
      "Epoch 49/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5755 - accuracy: 0.7513 - val_loss: 0.6305 - val_accuracy: 0.7307\n",
      "Epoch 50/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5722 - accuracy: 0.7534 - val_loss: 0.6350 - val_accuracy: 0.7301\n",
      "Epoch 51/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5731 - accuracy: 0.7532 - val_loss: 0.6321 - val_accuracy: 0.7319\n",
      "Epoch 52/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5713 - accuracy: 0.7534 - val_loss: 0.6349 - val_accuracy: 0.7267\n",
      "Epoch 53/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5723 - accuracy: 0.7550 - val_loss: 0.6264 - val_accuracy: 0.7333\n",
      "Epoch 54/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5693 - accuracy: 0.7563 - val_loss: 0.6281 - val_accuracy: 0.7327\n",
      "Epoch 55/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5682 - accuracy: 0.7571 - val_loss: 0.6323 - val_accuracy: 0.7318\n",
      "Epoch 56/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5678 - accuracy: 0.7556 - val_loss: 0.6310 - val_accuracy: 0.7303\n",
      "Epoch 57/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5637 - accuracy: 0.7583 - val_loss: 0.6251 - val_accuracy: 0.7307\n",
      "Epoch 58/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5691 - accuracy: 0.7541 - val_loss: 0.6247 - val_accuracy: 0.7354\n",
      "Epoch 59/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5621 - accuracy: 0.7609 - val_loss: 0.6275 - val_accuracy: 0.7331\n",
      "Epoch 60/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5651 - accuracy: 0.7572 - val_loss: 0.6278 - val_accuracy: 0.7317\n",
      "Epoch 61/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5643 - accuracy: 0.7587 - val_loss: 0.6293 - val_accuracy: 0.7307\n",
      "Epoch 62/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5632 - accuracy: 0.7589 - val_loss: 0.6257 - val_accuracy: 0.7304\n",
      "Epoch 63/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5648 - accuracy: 0.7595 - val_loss: 0.6304 - val_accuracy: 0.7306\n",
      "Epoch 64/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5654 - accuracy: 0.7570 - val_loss: 0.6240 - val_accuracy: 0.7343\n",
      "Epoch 65/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5591 - accuracy: 0.7617 - val_loss: 0.6280 - val_accuracy: 0.7319\n",
      "Epoch 66/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5633 - accuracy: 0.7594 - val_loss: 0.6268 - val_accuracy: 0.7318\n",
      "Epoch 67/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5616 - accuracy: 0.7593 - val_loss: 0.6281 - val_accuracy: 0.7296\n",
      "Epoch 68/70\n",
      "1266/1266 [==============================] - 6s 5ms/step - loss: 0.5630 - accuracy: 0.7594 - val_loss: 0.6260 - val_accuracy: 0.7372\n",
      "Epoch 69/70\n",
      "1266/1266 [==============================] - 7s 5ms/step - loss: 0.5593 - accuracy: 0.7628 - val_loss: 0.6284 - val_accuracy: 0.7343\n",
      "Epoch 70/70\n",
      "1266/1266 [==============================] - 7s 6ms/step - loss: 0.5551 - accuracy: 0.7649 - val_loss: 0.6260 - val_accuracy: 0.7330\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "model = nn5()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=64, epochs=70, validation_split=0.1)\n",
    "_ = model.evaluate(x=x_test, y=y_test, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
